{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data/vg_letters.csv\" # Output CSV written as part of the steps in parse_letters.ipynb\n",
    "letters = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"  # https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "embeddings = client.embeddings.create(model=EMBEDDING_MODEL, input=letters['Text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "All functions are obtained from OpenAI's cookbook: [Embedding Wikipedia articles for search](https://cookbook.openai.com/examples/embedding_wikipedia_articles_for_search). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-3.5-turbo\"  # only matters insofar as it selects which tokenizer to use\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
    "    \"\"\"Split a string in two, on a delimiter, trying to balance tokens on each side.\"\"\"\n",
    "    chunks = string.split(delimiter)\n",
    "    if len(chunks) == 1:\n",
    "        return [string, \"\"]  # no delimiter found\n",
    "    elif len(chunks) == 2:\n",
    "        return chunks  # no need to search for halfway point\n",
    "    else:\n",
    "        total_tokens = num_tokens(string)\n",
    "        halfway = total_tokens // 2\n",
    "        best_diff = halfway\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            left = delimiter.join(chunks[: i + 1])\n",
    "            left_tokens = num_tokens(left)\n",
    "            diff = abs(halfway - left_tokens)\n",
    "            if diff >= best_diff:\n",
    "                break\n",
    "            else:\n",
    "                best_diff = diff\n",
    "        left = delimiter.join(chunks[:i])\n",
    "        right = delimiter.join(chunks[i:])\n",
    "        return [left, right]\n",
    "\n",
    "\n",
    "def truncated_string(\n",
    "    string: str,\n",
    "    model: str,\n",
    "    max_tokens: int,\n",
    "    print_warning: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    encoded_string = encoding.encode(string)\n",
    "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
    "    if print_warning and len(encoded_string) > max_tokens:\n",
    "        print(f\"Warning: Truncated string from {len(encoded_string)} tokens to {max_tokens} tokens.\")\n",
    "    return truncated_string\n",
    "\n",
    "\n",
    "def split_strings_from_subsection(\n",
    "    string: str,\n",
    "    max_tokens: int = 1000,\n",
    "    model: str = GPT_MODEL,\n",
    "    max_recursion: int = 5,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a subsection into a list of subsections, each with no more than max_tokens.\n",
    "    Each subsection is a tuple of parent titles [H1, H2, ...] and text (str).\n",
    "    \"\"\"\n",
    "    num_tokens_in_string = num_tokens(string)\n",
    "    # if length is fine, return string\n",
    "    if num_tokens_in_string <= max_tokens:\n",
    "        return [string]\n",
    "    # if recursion hasn't found a split after X iterations, just truncate\n",
    "    elif max_recursion == 0:\n",
    "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
    "    # otherwise, split in half and recurse\n",
    "    else:\n",
    "        text = string\n",
    "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]:\n",
    "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
    "            if left == \"\" or right == \"\":\n",
    "                # if either half is empty, retry with a more fine-grained delimiter\n",
    "                continue\n",
    "            else:\n",
    "                # recurse on each half\n",
    "                results = []\n",
    "                for half in [left, right]:\n",
    "                    half_subsection = half\n",
    "                    half_strings = split_strings_from_subsection(\n",
    "                        half_subsection,\n",
    "                        max_tokens=max_tokens,\n",
    "                        model=model,\n",
    "                        max_recursion=max_recursion - 1,\n",
    "                    )\n",
    "                    results.extend(half_strings)\n",
    "                return results\n",
    "    # otherwise no split was found, so just truncate (should be very rare)\n",
    "    return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 144/864 [00:00<00:00, 1439.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617 tokens: http://www.vggallery.com/letters/088_V-T_076.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 864/864 [00:00<00:00, 1063.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 letters have more than 1600 tokens.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how many letters have more than 1600 tokens to see whether chunking is needed\n",
    "n = 0\n",
    "PRINTED_ONCE = False\n",
    "for i in tqdm(range(len(letters))):\n",
    "    t = num_tokens(letters['Text'][i])\n",
    "    if t > 1600:\n",
    "        n+=1 \n",
    "        # Output one example link for a long letter with more than 1600 tokens\n",
    "        if not PRINTED_ONCE:\n",
    "            print(f\"{t} tokens: {letters['PDF Link'][i]}\")\n",
    "            LONG_LETTER_IDX = i \n",
    "            PRINTED_ONCE = True\n",
    "\n",
    "print(f\"{n} letters have more than 1600 tokens.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nLetter 076 Isleworth, October 7 1876 Dear Theo,\\nIt is Saturday again and I write once more. How I long to see you again, Oh! my longing is sometimes so strong. Write soon, a little word as to how you are. Last Wednesday we took a long walk to a village an hour\\'s distance from here. The road led through meadows and fields, along hedges of hawthorn, full of blackberries and clematis, and here and there a large elm tree. It was so beautiful when the sun set behind the grey clouds, and the shadows were long. By chance we met the school of Mr. Stokes, where there are still several of the boys I knew. The clouds retained their red hue long after the sun had set and the dusk had settled over the fields, and we saw in the distance the lamps lit in the village. While I was writing to you, I was called to Mr. Jones, who asked if I would walk to London to collect some money for him. And when I came home in the evening, hurrah, there was a letter from Father with tidings about you. How I should like to be with you both, my boy. And thank God there is some improvement, though you are still weak. And you will be longing to see Mother, and now that I hear that you are going home with her, I think of the words of Conscience:\\n\"I have been ill, my mind was tired, my soul disillusioned and my body suffering. I whom God has endowed at least with moral energy and a strong instinct of affection, I fell in the abyss of the most bitter discouragement and I felt with horror how a deadly poison penetrated my stifled heart. I spent three months on the moors, you know that beautiful region where the soul retires within itself and enjoys a delicious rest,\\n where everything breathes calm and peace; where the soul in presence of God\\'s immaculate creation throws off the yoke of conventions, forgets society, and loosens its bonds, with the strength of renewed youth; where each thought takes the form of prayer, where everything that is not in harmony with fresh and free nature quits the heart. Oh, there the tired souls find rest, there the exhausted man regains his youthful strength. So I passed my days of illness . . .. And then the evening! To be seated before the big fireplace with one\\'s feet in the ashes, one\\'s eyes fixed on a star that sends its ray through the opening in the chimney as if to call me, or absorbed in vague dreams too much to look at the fire, to see the flames rise, flicker, and supplant one another as if desirous to lick the kettle with their tongues of fire, and to think that such is human life: to be born, to work, to love, to grow and to disappear.\" Mr. Jones has promised me that I shall not have to teach so much in future, but that I may work in his parish, visiting the people, talking with them, etc. May God give His blessing to me.\\n Now I am going to tell you about my walk to London. I left here at twelve o\\'clock in the morning and reached my destination between five and six. When I came into that part of the town where most of the picture galleries are, around the Strand, I met many acquaintances: it was dinnertime, so many were in the street, leaving the office or going back there. First I met a young clergyman who once preached here, and with whom I then became acquainted, and then the employee of Mr. Wallis, and then one of the Messrs.\\n Wallis himself, whom I used to visit now and then at his house, now he has two children; then I met Mr.\\n Reid and Mr. Richardson,  1 who are already old friends. Last year about this time Mr',\n",
       " 'Richardson was in Paris and we walked together to Père Lachaise.\\nAfter that I went to van Wisselingh, where I saw sketches for two church windows. In the middle of one window stands the portrait of a middle-aged lady, oh, such a noble face, with the words \"Thy will be done,\" over it, and in the other window the portrait of her daughter, with the words, \"Faith is the substance of things hoped for, the evidence of things not seen.\" 2 There, and in the gallery of Messrs. Goupil & Co., I saw beautiful pictures and drawings. It is such an intense delight to be so often reminded of Holland by art.\\nIn the City I went to see Mr. Gladwell and to St. Paul\\'s Church. And from the City to the other end of London, where I visited a boy who had left the school of Mr. Stokes because of illness and I found him quite well, playing in the street. Then to the place where I had to collect the money for Mr. Jones. The suburbs of London have a peculiar charm, between the little houses and gardens are open spots covered with grass and generally with a church or school or workhouse in the middle between the trees and shrubs,\\nand it can be so beautiful there, when the sun is setting red in the thin evening mist.\\nYesterday evening it was so, and afterwards I wished you could have seen those London streets when the twilight began to fall and the lamps were lit, and everybody went home; everything showed that it was Saturday night and in all that bustle there was peace, one felt the need of and the excitement at the approaching Sunday. Oh, those Sundays and all that is done and accomplished on those Sundays, it is such a comfort for those poor districts and crowded streets.\\nIn the City it was dark, but it was a beautiful walk along the row of churches one has to pass. Near the Strand I took a bus that took me quite a long way, it was already pretty late. I passed the little church of Mr.\\n Jones and saw in the distance another one, where at that hour a light was still burning; I entered and found it to be a very beautiful little Catholic church, where a few women were praying. Then I came to that dark park about which I have written you already and from there I saw in the distance the lights of Isleworth and the church with the ivy, and the churchyard with the weeping willows beside the Thames.\\n Tomorrow I shall get for the second time some small salary for my new work, and with it buy a pair of new boots and a new hat. And then, with God\\'s will, I shall go fitted out afresh.\\n In the London streets they sell scented violets everywhere, they flower here twice a year. I bought some for Mrs. Jones to make her forget the pipe I smoke now and then, especially late in the evening on the playground, but the tobacco here has a touch of gloom about it.\\nWell, Theo, try to get well soon and read this letter when Mother is sitting with you, because I should like to be with you both in thought. I cannot tell you how glad I am that Mr. Jones has promised to give me work in his parish, so that I shall find by and by what I want. I am longing so much for you. A handshake for yourself and one for Mother when she is sitting beside you. Many regards to the Roos family and to everyone I know, especially to Mr. Tersteeg. Tell Mother it was delightful to put on a pair of socks knitted by her, after that long walk to London.\\nThis morning the sun rose so beautifully again, I see it every morning when I wake the boys, à Dieu.\\n Your loving brother, Vincent 1.\\n Reid was an English art-dealer; Richardson was the travelling representative for Theo.\\'s firm.\\n2.\\n Hebrews XI i.\\n ']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how the splitting works for the long letter example\n",
    "split_strings_from_subsection(letters.Text[LONG_LETTER_IDX], max_tokens=1600, model=GPT_MODEL, max_recursion=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split letters into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "864it [00:06, 142.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split letters into chunks\n",
    "MAX_TOKENS = 1600\n",
    "vgogh_letter_chunks = []\n",
    "idxs = []\n",
    "\n",
    "for idx, letter in tqdm(letters.iterrows()):\n",
    "   split_result = split_strings_from_subsection(letter.Text, max_tokens=MAX_TOKENS)\n",
    "   vgogh_letter_chunks.extend(split_result)\n",
    "   len_chunks = len(split_result)\n",
    "   idxs.extend([idx] * len_chunks)\n",
    "\n",
    "# Join chunks to their letter metadata and drop the full, original text\n",
    "vgogh_letter_chunks_df = pd.DataFrame({'chunk': vgogh_letter_chunks, 'idx': idxs}).set_index('idx').join(letters).drop('Text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Origin</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>PDF Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nLetter 001 The Hague, c. 18 August 1872 Dear...</td>\n",
       "      <td>1</td>\n",
       "      <td>August, 1872</td>\n",
       "      <td>T-H</td>\n",
       "      <td>VvG</td>\n",
       "      <td>TvG</td>\n",
       "      <td>http://www.vggallery.com/letters/001_V-T_001.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nLetter 002 The Hague, 13 Dec 1872 Dear Theo,...</td>\n",
       "      <td>2</td>\n",
       "      <td>13 December 1872</td>\n",
       "      <td>T-H</td>\n",
       "      <td>VvG</td>\n",
       "      <td>TvG</td>\n",
       "      <td>http://www.vggallery.com/letters/002_V-T_002.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nLetter 003 The Hague, January 1873 My dear T...</td>\n",
       "      <td>3</td>\n",
       "      <td>January, 1873</td>\n",
       "      <td>T-H</td>\n",
       "      <td>VvG</td>\n",
       "      <td>TvG</td>\n",
       "      <td>http://www.vggallery.com/letters/003_V-T_003.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nLetter 004 The Hague, January 28 1873 Dear T...</td>\n",
       "      <td>4</td>\n",
       "      <td>28 January 1873</td>\n",
       "      <td>T-H</td>\n",
       "      <td>VvG</td>\n",
       "      <td>TvG</td>\n",
       "      <td>http://www.vggallery.com/letters/004_V-T_004.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nLetter 005 The Hague, 17 March 1873 Dear The...</td>\n",
       "      <td>5</td>\n",
       "      <td>17 March 1873</td>\n",
       "      <td>T-H</td>\n",
       "      <td>VvG</td>\n",
       "      <td>TvG</td>\n",
       "      <td>http://www.vggallery.com/letters/005_V-T_005.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk Number              Date  \\\n",
       "0  \\nLetter 001 The Hague, c. 18 August 1872 Dear...      1      August, 1872   \n",
       "1  \\nLetter 002 The Hague, 13 Dec 1872 Dear Theo,...      2  13 December 1872   \n",
       "2  \\nLetter 003 The Hague, January 1873 My dear T...      3     January, 1873   \n",
       "3  \\nLetter 004 The Hague, January 28 1873 Dear T...      4   28 January 1873   \n",
       "4  \\nLetter 005 The Hague, 17 March 1873 Dear The...      5     17 March 1873   \n",
       "\n",
       "  Origin From   To                                          PDF Link  \n",
       "0    T-H  VvG  TvG  http://www.vggallery.com/letters/001_V-T_001.pdf  \n",
       "1    T-H  VvG  TvG  http://www.vggallery.com/letters/002_V-T_002.pdf  \n",
       "2    T-H  VvG  TvG  http://www.vggallery.com/letters/003_V-T_003.pdf  \n",
       "3    T-H  VvG  TvG  http://www.vggallery.com/letters/004_V-T_004.pdf  \n",
       "4    T-H  VvG  TvG  http://www.vggallery.com/letters/005_V-T_005.pdf  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgogh_letter_chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vgogh_letter_chunks_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get embeddings with OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 99\n",
      "Batch 100 to 199\n",
      "Batch 200 to 299\n",
      "Batch 300 to 399\n",
      "Batch 400 to 499\n",
      "Batch 500 to 599\n",
      "Batch 600 to 699\n",
      "Batch 700 to 799\n",
      "Batch 800 to 899\n",
      "Batch 900 to 999\n",
      "Batch 1000 to 1099\n",
      "Batch 1100 to 1158\n"
     ]
    }
   ],
   "source": [
    "# You can submit up to 2048 embedding inputs per request\n",
    "# Choose a smaller number to be conservative, since big batches can take a long time to process\n",
    "BATCH_SIZE = 100  \n",
    "\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(vgogh_letter_chunks), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = vgogh_letter_chunks[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {min(len(vgogh_letter_chunks), batch_end-1)}\")\n",
    "    response = client.embeddings.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response.data):\n",
    "        assert i == be.index  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e.embedding for e in response.data]\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgogh_letter_chunks_df['embeddings'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to output CSV\n",
    "vgogh_letter_chunks_df.to_csv(\"data/letter_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annamatlin/miniconda3/envs/pdfparse/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "import umap \n",
    "\n",
    "# Reduce dimensionality of embeddings to 2D\n",
    "umap_model = umap.UMAP(n_components=5, metric='cosine', random_state=42).fit(vgogh_letter_chunks_df.embeddings.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annamatlin/miniconda3/envs/pdfparse/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning:\n",
      "\n",
      "n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter(vgogh_letter_chunks_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP-1\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP-2\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m                  color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrigin\u001b[39m\u001b[38;5;124m'\u001b[39m, facet_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom\u001b[39m\u001b[38;5;124m'\u001b[39m, facet_row\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     15\u001b[0m                  title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUMAP projection of Vincent van Gogh Letters\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m                  hover_data\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrigin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Show the plot\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pdfparse/lib/python3.10/site-packages/plotly/basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pdfparse/lib/python3.10/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Fit the UMAP model\n",
    "umap_embeddings = umap_model.transform(vgogh_letter_chunks_df.embeddings.tolist())\n",
    "\n",
    "# Add the UMAP embeddings to your DataFrame\n",
    "vgogh_letter_chunks_df['UMAP-1'] = umap_embeddings[:, 0]\n",
    "vgogh_letter_chunks_df['UMAP-2'] = umap_embeddings[:, 1]\n",
    "\n",
    "# Create an interactive scatter plot with Plotly Express\n",
    "fig = px.scatter(vgogh_letter_chunks_df, x='UMAP-1', y='UMAP-2', \n",
    "                 color='Origin', facet_col='From', facet_row='To', \n",
    "                 title='UMAP projection of Vincent van Gogh Letters',\n",
    "                 hover_data=['Origin', 'From', 'To'])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
